{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "Y8752wn5_m1k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rom google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YaZLWC2DAVxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "NDrCCPQkAY-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#performing data agumentation to train data\n",
        "x_train = train_datagen.flow_from_directory(\n",
        "    r'/content/drive/MyDrive/DATASET1/TRAIN_SET',target_size=(64, 64),batch_size=5,color_mode='rgb',class_mode='sparse')\n",
        "#performing data agumentation to test data\n",
        "x_test = test_datagen.flow_from_directory(\n",
        "    r'/content/drive/MyDrive/DATASET1/TEST_SET',\n",
        "    target_size=(64, 64),batch_size=5,color_mode='rgb',class_mode='sparse')"
      ],
      "metadata": {
        "id": "YcUsx1znA7ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.class_indices)"
      ],
      "metadata": {
        "id": "HF60lrB_BPcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}"
      ],
      "metadata": {
        "id": "8UCWo9lbBcLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test.class_indices)\n"
      ],
      "metadata": {
        "id": "-tp3EmHlBuWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "{'APPLES': 0, 'BANANA': 1, 'ORANGE': 2, 'PINEAPPLE': 3, 'WATERMELON': 4}\n"
      ],
      "metadata": {
        "id": "6Ae7wUDOCCU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counter({0: 606, 1: 445, 2: 479, 3: 621, 4: 495})"
      ],
      "metadata": {
        "id": "xbd-HGtLC4jy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing The Model Building Libraries"
      ],
      "metadata": {
        "id": "la83pO7PDDVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np#used for numerical analysis\n",
        "import tensorflow #open source used for both ML and DL for computation\n",
        "from tensorflow.keras.models import Sequential #it is a plain stack of layers\n",
        "from tensorflow.keras import layers #A layer consists of a tensor-in tensor-out computation function\n",
        "#Dense layer is the regular deeply connected neural network layer\n",
        "from tensorflow.keras.layers import Dense,Flatten\n",
        "#Faltten-used fot flattening the input or change the dimension\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout #Convolutional layer\n",
        "#MaxPooling2D-for downsampling the image\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "K7WZhhCkDPcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing The Model"
      ],
      "metadata": {
        "id": "qA1bcmjfDkmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Sequential()\n"
      ],
      "metadata": {
        "id": "GaModcTmDq9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding CNN Layer"
      ],
      "metadata": {
        "id": "xT2RC9xWDxR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "classifier.add(Flatten())\n",
        "\n",
        "classifier.add(Dense(units=128, activation='relu'))\n",
        "classifier.add(Dense(units=5, activation='softmax'))"
      ],
      "metadata": {
        "id": "MGgNcraOD3hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add Flatten Layer"
      ],
      "metadata": {
        "id": "SK-WoYZ6EJZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Flatten())"
      ],
      "metadata": {
        "id": "ChKfttAjEPzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add Dense Layer"
      ],
      "metadata": {
        "id": "nAC9_QyjEZZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Dense(units=128, activation='relu'))\n",
        "classifier.add(Dense(units=5, activation='softmax'))"
      ],
      "metadata": {
        "id": "-x6Ag-xWEfEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuring the learning process"
      ],
      "metadata": {
        "id": "0-9qR9QiElR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Dense(units=128, activation='relu'))\n",
        "classifier.add(Dense(units=5, activation='softmax'))"
      ],
      "metadata": {
        "id": "aR8VYGupEqHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.summary()"
      ],
      "metadata": {
        "id": "y_f1wDR9Ey3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model: \"sequential_1\"\n",
        "_________________________________________________________________\n",
        " Layer (type)                Output Shape              Param #   \n",
        "=================================================================\n",
        " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
        "                                                                 \n",
        " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
        " )                                                               \n",
        " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
        "                                                                 \n",
        " max_pooling2d_1 (MaxPooling  (None, 14, 14, 32)       0         \n",
        " 2D)                                                             \n",
        "                                                                 \n",
        " flatten (Flatten)           (None, 6272)              0         \n",
        "                                                                 \n",
        " dense (Dense)               (None, 128)               802944\n",
        "     \n",
        " dense_2 (Dense)             (None, 128)               768       \n",
        "                                                                 \n",
        " dense_3 (Dense)             (None, 5)                 645       \n",
        "                                                                 \n",
        " dense_4 (Dense)             (None, 128)               768       \n",
        "                                                                 \n",
        " dense_5 (Dense)             (None, 5)                 645       \n",
        "                                                                 \n",
        "=================================================================\n",
        "Total params: 816,559\n",
        "Trainable params: 816,559\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n"
      ],
      "metadata": {
        "id": "Yc8x4DkBFUOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "rgmtzczyGYX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "mYXnvy6PGgbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.fit_generator(generator=x_train,steps_per_epoch = len(x_train),\n",
        "                         epochs=20, validation_data=x_test,validation_steps = len(x_test))\n",
        "# No of images in test set"
      ],
      "metadata": {
        "id": "XmUreUOYGmFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
        "  \n",
        "Epoch 1/20\n",
        "530/530 [==============================] - 544s 1s/step - loss: 1.1523 - accuracy: 0.3983 - val_loss: 1.0435 - val_accuracy: 0.3612\n",
        "Epoch 2/20\n",
        "530/530 [==============================] - 31s 58ms/step - loss: 1.6353 - accuracy: 0.2302 - val_loss: 1.6361 - val_accuracy: 0.3612\n",
        "Epoch 3/20\n",
        "530/530 [==============================] - 29s 54ms/step - loss: 1.6045 - accuracy: 0.2241 - val_loss: 1.6341 - val_accuracy: 0.0000e+00\n",
        "Epoch 4/20\n",
        "530/530 [==============================] - 31s 58ms/step - loss: 1.6045 - accuracy: 0.2290 - val_loss: 1.6118 - val_accuracy: 0.3612\n",
        "Epoch 5/20\n",
        "530/530 [==============================] - 29s 55ms/step - loss: 1.6055 - accuracy: 0.2332 - val_loss: 1.6026 - val_accuracy: 0.3612\n",
        "Epoch 6/20\n",
        "Epoch 10/20\n",
        "530/530 [==============================] - 31s 59ms/step - loss: 1.6042 - accuracy: 0.2313 - val_loss: 1.6289 - val_accuracy: 0.3612\n",
        "Epoch 11/20\n",
        "530/530 [==============================] - 29s 56ms/step - loss: 1.6041 - accuracy: 0.2260 - val_loss: 1.6062 - val_accuracy: 0.3612\n",
        "Epoch 12/20\n",
        "530/530 [==============================] - 31s 59ms/step - loss: 1.6047 - accuracy: 0.2256 - val_loss: 1.6059 - val_accuracy: 0.3612\n",
        "530/530 [==============================] - 31s 59ms/step - loss: 1.6047 - accuracy: 0.2256 - val_loss: 1.6059 - val_accuracy: 0.3612\n",
        "Epoch 13/20\n",
        "530/530 [==============================] - 33s 63ms/step - loss: 1.6024 - accuracy: 0.2313 - val_loss: 1.5884 - val_accuracy: 0.3612\n",
        "Epoch 14/20\n",
        "530/530 [==============================] - 30s 56ms/step - loss: 1.6040 - accuracy: 0.2290 - val_loss: 1.6144 - val_accuracy: 0.3612\n",
        "Epoch 15/20\n",
        "530/530 [==============================] - 31s 58ms/step - loss: 1.6025 - accuracy: 0.2317 - val_loss: 1.6208 - val_accuracy: 0.3612\n",
        "Epoch 16/20\n",
        "530/530 [==============================] - 29s 55ms/step - loss: 1.6030 - accuracy: 0.2328 - val_loss: 1.6371 - val_accuracy: 0.0000e+00\n",
        "Epoch 17/20\n",
        "530/530 [==============================] - 29s 55ms/step - loss: 1.6033 - accuracy: 0.2305 - val_loss: 1.6265 - val_accuracy: 0.3612\n",
        "Epoch 18/20\n",
        "530/530 [==============================] - 31s 59ms/step - loss: 1.6027 - accuracy: 0.2339 - val_loss: 1.5975 - val_accuracy: 0.3612\n",
        "Epoch 19/20\n",
        "530/530 [==============================] - 29s 55ms/step - loss: 1.6027 - accuracy: 0.2324 - val_loss: 1.6311 - val_accuracy: 0.0000e+00\n",
        "Epoch 20/20\n",
        "530/530 [==============================] - 34s 64ms/step - loss: 1.6021 - accuracy: 0.2336 - val_loss: 1.6032 - val_accuracy: 0.3612\n"
      ],
      "metadata": {
        "id": "YQKqj6BmGwAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the Model"
      ],
      "metadata": {
        "id": "WaOWD-DRH7WU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.save('nutrition.h5')"
      ],
      "metadata": {
        "id": "OqPsGIKpICkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicition"
      ],
      "metadata": {
        "id": "jtcNTyknINJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "sfdiiKhQIVLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img(\"/content/drive/MyDrive/DATASET1/TEST_SET/ORANGE/38_100.jpg\",target_size= (64,64))"
      ],
      "metadata": {
        "id": "ACcJQkyMIaA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=image.img_to_array(img)"
      ],
      "metadata": {
        "id": "CrzauICvIiXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "9qmjRcR0ImUv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "array([[[255., 253., 240.],\n",
        "        [255., 252., 254.],\n",
        "        [255., 252., 255.],\n",
        "        ...,\n",
        "        [255., 255., 255.],\n",
        "        [255., 255., 255.],\n",
        "        [255., 255., 255.]],\n",
        "\n",
        "       [[250., 255., 254.],\n",
        "        [253., 253., 255.],\n",
        "        [253., 253., 255.],\n",
        "        ...,\n",
        "        [255., 255., 255.],\n",
        "        [255., 255., 255.],\n",
        "        [255., 255., 255.]],\n",
        "\n",
        "       [[247., 255., 255.],\n",
        "        [251., 254., 255.],\n",
        "        [253., 252., 255.],\n",
        "        ...,\n",
        "        [255., 255., 255.],\n",
        "        [255., 255., 255.],\n",
        "        [255., 255., 255.]],\n",
        "\n",
        "       ...,\n",
        "\n",
        "       [[255., 255., 255.],\n",
        "        [255., 255., 255.],\n",
        "        [255., 255., 255.],\n",
        "        ...,\n",
        "        [255., 255., 255.],\n",
        "        [255., 255., 255.],\n",
        "        [255., 255., 255.]],\n",
        "        [[255., 255., 255.],\n",
        "        [255., 255., 255.],\n",
        "        [255., 255., 255.],\n",
        "        ...,\n",
        "        [255., 255., 255.],\n",
        "        [255., 255., 255.],\n",
        "        [255., 255., 255.]]], dtype=float32)"
      ],
      "metadata": {
        "id": "m1g4zn8FJLyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.ndim"
      ],
      "metadata": {
        "id": "njci4u1pJhyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3"
      ],
      "metadata": {
        "id": "GztAiNL6Joll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.expand_dims(x,axis=0)"
      ],
      "metadata": {
        "id": "1q-fxTgYJtWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.ndim"
      ],
      "metadata": {
        "id": "DJDU-tmgJxfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4"
      ],
      "metadata": {
        "id": "lDEdqvaHJ0Xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = classifier.predict(x)"
      ],
      "metadata": {
        "id": "0WdXo-stJ1ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1/1 [==============================] - 0s 142ms/step"
      ],
      "metadata": {
        "id": "jyIQZZ9HJ5ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "id": "8iT0EyOgJ-mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "array([[0.21279842, 0.17572571, 0.17553818, 0.24457753, 0.19136012]],\n",
        "      dtype=float32)"
      ],
      "metadata": {
        "id": "MMeEx8rkKCY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels=['APPLES', 'BANANA', 'ORANGE','PINEAPPLE','WATERMELON']\n",
        "labels[np.argmax(pred)]"
      ],
      "metadata": {
        "id": "BrddZGzWKHcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "'PINEAPPLE'"
      ],
      "metadata": {
        "id": "7N9c-UeVKLXI"
      }
    }
  ]
}